# JAVA基础

## Java知识点

### HashMap

#### 构造函数

   HashMap有四个构造方法。

   1. HashMap()

   ```java
   // 1.无参构造方法
   // 构造一个空的HashMap，初始容量为16，负载因子为0.75
   public HashMap() {
   	this.loadFactor = DEFAULT_LOAD_FACTOR;
   }   
   ```

   2. HashMap(int initialCapacity)
   ```java
   // 2.构造一个初始容量为initialCapacity，负载因子为0.75的空的HashMap
   public HashMap(int initialCapacity) {
       this(initialCapacity,DEFAULT_LOAD_FACTOR)；
   }
   ```

   3. HashMap(int initialCapacity,float loadFactor)
   ```java
   // 3.构造一个空的初始容量为initialCapacity，负载因子为loadFactor的HashMap
   public HashMap(int initialCapacity,float loadFactor) {
       if(initialCapacity < 0) {
           throw new IllegalArgumentException("Illegal initial capacity: " +
                                                  initialCapacity);
       }    
       if(loadFactor > MAXIMUM_CAPACITY) {
           loadFactor = MAXIMUM_CAPACITY;
       }
       if(loadFactor <= 0 || Float.isNaN(loadFactor)) {
           throw new IllegalArgumentException("Illegal load factor: " +
                                                  loadFactor);
       }
       this.loadFactor = loadFactor;
       // threshold = capacity * loadFactor
       // 当HashMap的size到了threshold的时,就要进行扩容
       // HashMap要求容量必须是2的幂
       // tableSizeFor()的主要功能是返回一个比给定整数大且接近的2的幂次方数
       this.threshold = tableSizeFor(initialCapacity);
   }
   
   static final int tableSizeFor(int cap) {
       int n = cap - 1;
       n |= n >>> 1;
       n |= n >>> 2;
       n |= n >>> 4;
       n |= n >>> 8;
       n |= n >>> 16;
   	return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
   }
   ```

   4. HashMap(Map<? extends K,? extends V>)
   ```java
   // 4.构造一个和指定Map有相同mappings的HashMap
   // 初始容量能充足的容下指定的Map，负载因子为0.75
   public HashMap(Map<? extends K,? extends V>) {
       this.loadFactor = DEFAULT_LOAD_FACTOR;
       putMapEntries(m, false);
   }
   
   /**
    * 将m的所有元素存入本HashMap实例中
    */
   final void putMapEntries(Map<? extends K,? extends V> m,boolean evict) {
   	//得到m中元素的个数
       int s = m.size();  
       //当m中有元素时，则需将map中元素放入本HashMap实例
       if(s > 0) {
           //判断table是否已经初始化，如果为初始化，则先初始化一些变量
           //table初始化是在put时
           if(table == null) {
               //根据待插入的map的size计算要创建的HashMap的容量
               float ft = ((float)s / loadFactor);
               int t = ((ft < (float)MAXIMUM_CAPACITY)?
                       (int)ft : MAXIMUM_CAPACITY);
           } else if(s > threshold) {
               //如果table初始化过，因为别的函数也会调用它，所以有可能HashMap已经被初始化过了
               //判断待插入的map的size,若size大于threshold，则先进行resize()，进行扩容
               resize();
           }
           //然后开始遍历待插入的map，将每一个元素插入到本HashMap实例
           for(Map.Entry<? extends K,? extends V> e : m.entrySet()) {
               K key = e.getKey();
               V value = e.getValue();
               //put(K,V)也是调用puVal()函数进行元素的插入
               putVal(hash(key),key,value,falue,evict);
           }
       }
   }
   ```

#### 扩容resize()

   + 什么时候扩容

     在put操作，即向容器中添加元素时，判断当前容器中元素的个数是否达到阈值（当前数组长度乘以加载因子的值），

     若是，则进行扩容

   + 扩容
   
     就是重新计算容量，而这个扩容是计算出所需容器大小之后重新定义一个新的容器，讲原来容器中的元素放入其中。

   ``` java
   final Node<K,V>[] resize() {
       //保存当前table
       Node<K,V>[] oldTab = table;
       //保存当前table的容量
       int oldCap = (oldTab == null) ? 0 : oldTab.length;
       //保存当前阈值
       int oldThr = threshold;
       //初始化新的table容量和阈值
       int newCap, newThr = 0;
       /*
       1.resize()在size > threshold时被调用。oldCap大于0代表原来的table表非空，
       oldCap为原来的大小，oldThr为oldCap * load_factor
       */
       if (oldCap > 0) {
           // 若旧table容量已超过最大容量，更新阈值为Interger.MAX_VALUE(最大整形值),这样以后就不会自动扩容了
           if (oldCap >= MAXIMUM_CAPACITY) {
               threshold = Integer.MAX_VALUE;
               return oldTab;
           }
           // 容量翻倍，使用左移，效率更高
           else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                     oldCap >= DEFAULT_INITIAL_CAPACITY) {
               //阈值翻倍
                newThr = oldThr << 1; 
           }
        }
       /*
       2.resize()在table为空的时候被调用。oldCap <= 0 且 oldThr > 0，代表用户创建了一个HashMap，
       但是调用了有参构造函数，导致oldTab = null,oldCap = 0,oldThr > 0
       */
        else if (oldThr > 0) {// initial capacity was placed in threshold
            //当table没初始化时,threshold持有初始容量(threshold = tableSizeFor(t))
            newCap = oldThr;
        }
       /*
       3.resize()在table为空时调用。oldCap <=0 且oldThr = 0，用户调用HashMap()构造函数创建的HashMap，所有值均采用默认值，oldTab（Table）表为空，oldCap为0，oldThr等于
       */
        else {               // zero initial threshold signifies using defaults
            newCap = DEFAULT_INITIAL_CAPACITY;
            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
        }
        // 计算新的resize上限
        if (newThr == 0) {
            float ft = (float)newCap * loadFactor;
            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                      (int)ft : Integer.MAX_VALUE);
        }
       threshold = newThr;
       @SuppressWarnings({"rawtypes"，"unchecked"})
       //初始化table
       Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
       table = newTab;
       if (oldTab != null) {
           // 把oldTab中的节点reHash到newTab中去
           for (int j = 0; j < oldCap; ++j) {
               Node<K,V> e;
               if ((e = oldTab[j]) != null) {  
                   //释放旧oldTab节点的对象引用
                   oldTab[j] = null;
                   //若节点是单个节点，直接在newTab中进行重定位
                   if (e.next == null) {
                       newTab[e.hash & (newCap - 1)] = e;
                   }
                   //若节点是TreeNode节点，要进行红黑树的rehash操作
                   else if (e instanceof TreeNode) {
                       ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                   }
                   //若是链表，进行链表的rehash操作
                   else {
                       Node<K,V> loHead = null, loTail = null;
                       Node<K,V> hiHead = null, hiTail = null;
                       Node<K,V> next;
                       //将同一桶中的元素根据(e.hash & oldCap)是否为0进行分割,
                       //分成两个不同的链表，完成rehash
                       do {
                           next = e.next;
                           // 根据算法e.hash & oldCap判断节点位置rehash后是否发生变化
                           // 最高位==0，这是索引不变的链表
                           if ((e.hash & oldCap) == 0) {
                               if (loTail == null) {
                                   loHead = e;
                               } else {
                                   loTail.next = e;
                               }
                               loTail = e;
                           }
                           //最高位==1，这是索引发生改变的链表
                           else {
                               if (hiTail == null)
                                   hiHead = e;
                               else
                                   hiTail.next = e;
                               hiTail = e;
                           }
                       } while ((e = next) != null);
                       //原bucket位置的为指针不为空
                       if (loTail != null) {
                           loTail.next = null;
                           newTab[j] = loHead;//链表头指针放在新桶的相同下标(j)处
                       }
                       // 原索引+oldCap放到bucket里
                       if (hiTail != null) {
                           hiTail.next = null;
                           //rehash后节点新的位置一定为原来基础上加上oldCap
                           newTab[j + oldCap] = hiHead;
                       }
                   }
               }
           }
       }
       return newTab;
   }
   
   final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                      boolean evict) {
           Node<K,V>[] tab; Node<K,V> p; int n, i;
           // 如果存储元素的table为空，则进行必要字段的初始化
           if ((tab = table) == null || (n = tab.length) == 0) {
               n = (tab = resize()).length;    // 获取长度（16）
           }
           // 如果根据hash值获取的结点为空，则新建一个结点
           if ((p = tab[i = (n - 1) & hash]) == null)      // 此处 & 代替了 % （除法散列法进行散列）
               tab[i] = newNode(hash, key, value, null);
           // 这里的p结点是根据hash值算出来对应在数组中的元素
           else {
               Node<K,V> e; K k;
               // 如果新插入的结点和table中p结点的hash值，key值相同的话
               if (p.hash == hash &&
                   ((k = p.key) == key || (key != null && key.equals(k))))
                   e = p;
               // 如果是红黑树结点的话，进行红黑树插入
               else if (p instanceof TreeNode)
                   e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
               else {
                   for (int binCount = 0; ; ++binCount) {
                       // 代表这个单链表只有一个头部结点，则直接新建一个结点即可
                       if ((e = p.next) == null) {
                           p.next = newNode(hash, key, value, null);
                           // 链表长度大于8时，将链表转红黑树
                           if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                               treeifyBin(tab, hash);
                           break;
                       }
                       if (e.hash == hash &&
                           ((k = e.key) == key || (key != null && key.equals(k))))
                           break;
                       // 及时更新p
                       p = e;
                   }
               }
               // 如果存在这个映射就覆盖
               if (e != null) { // existing mapping for key
                   V oldValue = e.value;
                   // 判断是否允许覆盖，并且value是否为空
                   if (!onlyIfAbsent || oldValue == null)
                       e.value = value;
                   afterNodeAccess(e);     // 回调以允许LinkedHashMap后置操作
                   return oldValue;
               }
           }
           ++modCount;     // 更改操作次数
           if (++size > threshold)     // 大于临界值
               // 将数组大小设置为原来的2倍，并将原先的数组中的元素放到新数组中
               // 因为有链表，红黑树之类，因此还要调整他们
               resize();  
           // 回调以允许LinkedHashMap后置操作
           afterNodeInsertion(evict);
           return null;
   }
   
   ```

#### 1.7和1.8的HashMap的不同点

   1. JDK1.7用的是头插法，而JDK1.8及之后使用的都是尾插法，那么为什么要这样做呢？因为JDK1.7是用单链表进行的纵向延伸，当采用头插法就是能够提高插入的效率，但是也会容易出现逆序且环形链表死循环问题。但是在JDK1.8之后是因为加入了红黑树使用尾插法，能够避免出现逆序且链表死循环的问题。
   2. 扩容后数据存储位置的计算方式也不一样：
   + 在JDK1.7的时候是直接用hash值和需要扩容的二进制数进行&amp;（这里就是为什么扩容的时候为啥一定必须是2的多少次幂的原因所在，因为如果只有2的n次幂的情况时最后一位二进制数才一定是1，这样能最大程度减少hash碰撞）
   + 而在JDK1.8的时候直接用了JDK1.7的时候计算的规律，也就是扩容前的原始位置+扩容的大小值=JDK1.8的计算方式，而不再是JDK1.7的那种异或的方法。但是这种方式就相当于只需要判断Hash值的新增参与运算的位是0还是1就直接迅速计算出了扩容后的储存方式。
   3. JDK1.7的时候使用的是数组+ 单链表的数据结构。但是在JDK1.8及之后时，使用的是数组+链表+红黑树的数据结构（当链表的深度达到8的时候，也就是默认阈值，就会自动扩容把链表转成红黑树的数据结构来把时间复杂度从O（N）变成O（logN）提高了效率）。

#### HashMap实现为什么使用红黑树
   + 同一Hash值存储在一个链表里，当元素过多时，通过key值依次查找的效率会降低，而红黑树的平均查找长度为log(n),当链表长度为8时，链表平均查找长度为n/2即8/4，不如红黑树的log(8)=3,这个时候将链表转换为红黑树
   + 虽然AVL树（平衡二叉树）提供更快的查找速度，但是红黑树更加适合插入修改密集型任务，因为AVL树的旋转比红黑树的旋转更加难以平衡和调试。

   





